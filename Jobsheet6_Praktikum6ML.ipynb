{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMW9VL1fWk1Fa2x1zUME8ZI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/azzazhr/Machine_Learning/blob/main/Jobsheet6_Praktikum6ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Nama : Azzahra Attaqina**\n",
        "\n",
        "### **NIM  : 2341720224**\n",
        "\n",
        "### **Kelas : TI-3B**"
      ],
      "metadata": {
        "id": "A6OdH9Yvb4Fw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ANN (Approximate Nearest Neightbors)**"
      ],
      "metadata": {
        "id": "Pk06VHhPb8MY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lakukan percobaan penggunaan ANNOY, FAISS, dan HNSWLIB pada dataset sekunder berukuran besar (Micro Spotify) pada link berikut: https://www.kaggle.com/datasets/bwandowando/spotify-songs-with-attributes-and-lyrics/data . Download data dan load CSV filenya (pilih dataset yg pertama dari dua dataset). pilih hanya fitur numerik saja, dan lakukan normalisasi menggunakan StandardScaler. Lakukan pencarian track terdekat dan bandingkan hasilnya.**"
      ],
      "metadata": {
        "id": "2LjAPiuHb80N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install annoy\n",
        "!pip install faiss-cpu\n",
        "!pip install  hnswlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-KN9q5E4zvY",
        "outputId": "6608437c-27f2-4059-819d-c63e1229426e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: annoy in /usr/local/lib/python3.12/dist-packages (1.17.3)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Requirement already satisfied: hnswlib in /usr/local/lib/python3.12/dist-packages (0.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from hnswlib) (2.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import faiss\n",
        "from annoy import AnnoyIndex\n",
        "import hnswlib\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from google.colab import drive\n",
        "\n",
        "# -------------------------------\n",
        "# Load dataset\n",
        "# -------------------------------\n",
        "drive.mount('/content/drive')\n",
        "df = pd.read_csv('/content/drive/MyDrive/ML2025/songs_with_attributes_and_lyrics.csv')  # ganti path sesuai lokasi file\n",
        "features = ['danceability', 'energy', 'loudness', 'speechiness',\n",
        "            'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']\n",
        "X = df[features].values\n",
        "\n",
        "# Standarisasi fitur\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "k = 10  # jumlah nearest neighbors\n",
        "\n",
        "# -------------------------------\n",
        "# Exact Nearest Neighbor (brute-force)\n",
        "# -------------------------------\n",
        "start = time.time()\n",
        "nn = NearestNeighbors(n_neighbors=k, algorithm='brute', metric='euclidean')\n",
        "nn.fit(X_scaled)\n",
        "dist_exact, idx_exact = nn.kneighbors(X_scaled)\n",
        "time_exact = time.time() - start\n",
        "print(f\"Exact NN done in {time_exact:.3f} s\")\n",
        "\n",
        "# -------------------------------\n",
        "# Annoy\n",
        "# -------------------------------\n",
        "start = time.time()\n",
        "f = X_scaled.shape[1]\n",
        "index_annoy = AnnoyIndex(f, 'euclidean')\n",
        "for i, v in enumerate(X_scaled):\n",
        "    index_annoy.add_item(i, v)\n",
        "index_annoy.build(10)\n",
        "idx_annoy = [index_annoy.get_nns_by_vector(v, k) for v in X_scaled]\n",
        "time_annoy = time.time() - start\n",
        "print(f\"Annoy done in {time_annoy:.3f} s\")\n",
        "\n",
        "# -------------------------------\n",
        "# HNSW\n",
        "# -------------------------------\n",
        "start = time.time()\n",
        "p_hnsw = hnswlib.Index(space='l2', dim=X_scaled.shape[1])\n",
        "p_hnsw.init_index(max_elements=X_scaled.shape[0], ef_construction=200, M=16)\n",
        "p_hnsw.add_items(X_scaled)\n",
        "p_hnsw.set_ef(200)\n",
        "idx_hnsw, dist_hnsw = p_hnsw.knn_query(X_scaled, k=k)\n",
        "time_hnsw = time.time() - start\n",
        "print(f\"HNSW done in {time_hnsw:.3f} s\")\n",
        "\n",
        "# -------------------------------\n",
        "# FAISS IVF\n",
        "# -------------------------------\n",
        "start = time.time()\n",
        "quantizer = faiss.IndexFlatL2(X_scaled.shape[1])\n",
        "index_faiss = faiss.IndexIVFFlat(quantizer, X_scaled.shape[1], nlist=100, metric=faiss.METRIC_L2)\n",
        "index_faiss.train(X_scaled)\n",
        "index_faiss.add(X_scaled)\n",
        "index_faiss.nprobe = 10\n",
        "dist_faiss, idx_faiss = index_faiss.search(X_scaled, k)\n",
        "time_faiss = time.time() - start\n",
        "print(f\"FAISS IVF done in {time_faiss:.3f} s\")\n",
        "\n",
        "# -------------------------------\n",
        "# Contoh tampilkan top-5 neighbors dari item pertama\n",
        "# -------------------------------\n",
        "print(\"\\nTop-5 neighbors for first song:\")\n",
        "print(f\"Exact NN: {idx_exact[0][:5]}\")\n",
        "print(f\"Annoy:    {idx_annoy[0][:5]}\")\n",
        "print(f\"HNSW:     {idx_hnsw[0][:5]}\")\n",
        "print(f\"FAISS:    {idx_faiss[0][:5]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "ZWoRYlKBcH_Y",
        "outputId": "abe7bc07-50e6-4cb7-cf17-f4c1f8c10469"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Exact NN done in 5900.289 s\n",
            "Annoy done in 77.724 s\n",
            "HNSW done in 393.580 s\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "add_ref_in_constructor.<locals>.replacement_init() got an unexpected keyword argument 'nlist'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-540851700.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0mquantizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfaiss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIndexFlatL2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_scaled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m \u001b[0mindex_faiss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfaiss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIndexIVFFlat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquantizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_scaled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnlist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfaiss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMETRIC_L2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0mindex_faiss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0mindex_faiss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: add_ref_in_constructor.<locals>.replacement_init() got an unexpected keyword argument 'nlist'"
          ]
        }
      ]
    }
  ]
}