{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMnMj3mJJ0w2BaaOkeyVkOg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/azzazhr/Machine_Learning/blob/main/Jobsheet13_ANN%26EvaluasiClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Nama : Azzahra Attaqina**\n",
        "\n",
        "### **NIM  : 2341720224**\n",
        "\n",
        "### **Kelas : TI-3B**"
      ],
      "metadata": {
        "id": "7x1mfqQqn3S6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**JOBSHEET 13 – ANN DAN EVALUASI CLASSIFIER**"
      ],
      "metadata": {
        "id": "tLDnEvw7n4Zd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PRAKTIKUM 1**"
      ],
      "metadata": {
        "id": "DLPb77Tun9vb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# Langkah 1 - Buat dataset sederhana (XOR).\n",
        "# ========================================\n",
        "import numpy as np\n",
        "\n",
        "# Dataset XOR\n",
        "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "y = np.array([[0],[1],[1],[0]])\n",
        "\n",
        "# Parameter\n",
        "input_size = 2\n",
        "hidden_size = 2\n",
        "output_size = 1\n",
        "lr = 0.1\n",
        "\n",
        "# ========================================\n",
        "# Langkah 2 - Inisialisasi bobot dan bias\n",
        "# ========================================\n",
        "\n",
        "# Inisialisasi bobot\n",
        "W1 = np.random.randn(input_size, hidden_size)\n",
        "b1 = np.zeros((1, hidden_size))\n",
        "W2 = np.random.randn(hidden_size, output_size)\n",
        "b2 = np.zeros((1, output_size))\n",
        "\n",
        "# Fungsi aktivasi\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "# =========================================\n",
        "# Langkah 3 - Implementasikan forward pass.\n",
        "# =========================================\n",
        "\n",
        "# Training\n",
        "for epoch in range(10000):\n",
        "    # Forward pass\n",
        "    z1 = np.dot(X, W1) + b1\n",
        "    a1 = sigmoid(z1)\n",
        "    z2 = np.dot(a1, W2) + b2\n",
        "    a2 = sigmoid(z2)\n",
        "\n",
        "    # =====================================================\n",
        "    # Langkah 4 - Hitung error dan lakukan backpropagation.\n",
        "    # =====================================================\n",
        "\n",
        "    # Hitung error\n",
        "    error = y - a2\n",
        "\n",
        "    # Backpropagation\n",
        "    d_a2 = error * sigmoid_derivative(a2)\n",
        "    d_W2 = np.dot(a1.T, d_a2)\n",
        "    d_b2 = np.sum(d_a2, axis=0, keepdims=True)\n",
        "\n",
        "    d_a1 = np.dot(d_a2, W2.T) * sigmoid_derivative(a1)\n",
        "    d_W1 = np.dot(X.T, d_a1)\n",
        "    d_b1 = np.sum(d_a1, axis=0, keepdims=True)\n",
        "\n",
        "    # =====================================================\n",
        "    # Langkah 5 - Update bobot menggunakan gradient descent.\n",
        "    # =====================================================\n",
        "\n",
        "    # Update bobot\n",
        "    W1 += lr * d_W1\n",
        "    b1 += lr * d_b1\n",
        "    W2 += lr * d_W2\n",
        "    b2 += lr * d_b2\n",
        "\n",
        "    if epoch % 1000 == 0:\n",
        "        loss = np.mean(np.square(error))\n",
        "        print(f\"Epoch {epoch}, Loss: {loss}\")\n",
        "\n",
        "# Output akhir\n",
        "print(\"Prediksi:\")\n",
        "print(a2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCMnHrqMrXtN",
        "outputId": "9f1847ab-5115-4e4b-e3ce-fcb41cd514f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.24640842661985576\n",
            "Epoch 1000, Loss: 0.19358356514096486\n",
            "Epoch 2000, Loss: 0.1500071296308042\n",
            "Epoch 3000, Loss: 0.05301419224429814\n",
            "Epoch 4000, Loss: 0.017719077592599386\n",
            "Epoch 5000, Loss: 0.009298045883491026\n",
            "Epoch 6000, Loss: 0.006059009189500078\n",
            "Epoch 7000, Loss: 0.004419179044894149\n",
            "Epoch 8000, Loss: 0.0034476618873441134\n",
            "Epoch 9000, Loss: 0.002811670751670903\n",
            "Prediksi:\n",
            "[[0.04168635]\n",
            " [0.95381462]\n",
            " [0.95371388]\n",
            " [0.05874874]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TUGAS 1**"
      ],
      "metadata": {
        "id": "9-4Nxy95sF-X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Ubah jumlah neuron hidden layer menjadi 3.\n",
        "\n",
        "- Bandingkan hasil loss dengan konfigurasi awal.\n",
        "\n",
        "- Tambahkan fungsi aktivasi ReLU dan bandingkan hasil."
      ],
      "metadata": {
        "id": "5ucUd3qRsIRh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Ubah jumlah neuron hidden layer menjadi 3.**"
      ],
      "metadata": {
        "id": "r3gLAqIetT2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# Langkah 1 - Buat dataset sederhana (XOR).\n",
        "# ========================================\n",
        "import numpy as np\n",
        "\n",
        "# Dataset XOR\n",
        "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "y = np.array([[0],[1],[1],[0]])\n",
        "\n",
        "# Parameter\n",
        "input_size = 2\n",
        "hidden_size = 3 # <--DIUBAH (dari 2 menjadi 3)\n",
        "output_size = 1\n",
        "lr = 0.1\n",
        "\n",
        "# ========================================\n",
        "# Langkah 2 - Inisialisasi bobot dan bias\n",
        "# ========================================\n",
        "\n",
        "# Inisialisasi bobot\n",
        "W1 = np.random.randn(input_size, hidden_size)\n",
        "b1 = np.zeros((1, hidden_size))\n",
        "W2 = np.random.randn(hidden_size, output_size)\n",
        "b2 = np.zeros((1, output_size))\n",
        "\n",
        "# Fungsi aktivasi\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "# =========================================\n",
        "# Langkah 3 - Implementasikan forward pass.\n",
        "# =========================================\n",
        "\n",
        "# Training\n",
        "for epoch in range(10000):\n",
        "    # Forward pass\n",
        "    z1 = np.dot(X, W1) + b1\n",
        "    a1 = sigmoid(z1)\n",
        "    z2 = np.dot(a1, W2) + b2\n",
        "    a2 = sigmoid(z2)\n",
        "\n",
        "    # =====================================================\n",
        "    # Langkah 4 - Hitung error dan lakukan backpropagation.\n",
        "    # =====================================================\n",
        "\n",
        "    # Hitung error\n",
        "    error = y - a2\n",
        "\n",
        "    # Backpropagation\n",
        "    d_a2 = error * sigmoid_derivative(a2)\n",
        "    d_W2 = np.dot(a1.T, d_a2)\n",
        "    d_b2 = np.sum(d_a2, axis=0, keepdims=True)\n",
        "\n",
        "    d_a1 = np.dot(d_a2, W2.T) * sigmoid_derivative(a1)\n",
        "    d_W1 = np.dot(X.T, d_a1)\n",
        "    d_b1 = np.sum(d_a1, axis=0, keepdims=True)\n",
        "\n",
        "    # =====================================================\n",
        "    # Langkah 5 - Update bobot menggunakan gradient descent.\n",
        "    # =====================================================\n",
        "\n",
        "    # Update bobot\n",
        "    W1 += lr * d_W1\n",
        "    b1 += lr * d_b1\n",
        "    W2 += lr * d_W2\n",
        "    b2 += lr * d_b2\n",
        "\n",
        "    if epoch % 1000 == 0:\n",
        "        loss = np.mean(np.square(error))\n",
        "        print(f\"Epoch {epoch}, Loss: {loss}\")\n",
        "\n",
        "# Output akhir\n",
        "print(\"Prediksi:\")\n",
        "print(a2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25bjqWWosVAP",
        "outputId": "00fecba3-529b-44c8-b3e2-3e3bd420e6ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.2857569475593884\n",
            "Epoch 1000, Loss: 0.24622883794401407\n",
            "Epoch 2000, Loss: 0.2148107117213894\n",
            "Epoch 3000, Loss: 0.1561068291240328\n",
            "Epoch 4000, Loss: 0.04827438408264683\n",
            "Epoch 5000, Loss: 0.015636706319027138\n",
            "Epoch 6000, Loss: 0.00812959443456651\n",
            "Epoch 7000, Loss: 0.005265764085151223\n",
            "Epoch 8000, Loss: 0.0038234597202794615\n",
            "Epoch 9000, Loss: 0.0029724499458485577\n",
            "Prediksi:\n",
            "[[0.03671893]\n",
            " [0.95352437]\n",
            " [0.95368063]\n",
            " [0.06337923]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Bandingkan hasil loss dengan konfigurasi awal.**"
      ],
      "metadata": {
        "id": "EJmg6_NntWrL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Konfigurasi Awal (hidden_size = 2): Ini adalah konfigurasi minimalis untuk menyelesaikan masalah XOR. Model ini cukup untuk belajar, dan loss akan turun secara signifikan (misalnya, mungkin berakhir di Loss: 0.002...).\n",
        "\n",
        "- Konfigurasi Tugas (hidden_size = 3): Dengan menambah neuron, model memiliki lebih banyak \"ruang\" untuk menemukan solusi yang lebih optimal. Ia bisa menyesuaikan bobotnya dengan lebih presisi.\n",
        "\n",
        "\n",
        "**Kesimpulan Perbandingan:**\n",
        "\n",
        "Model dengan hidden_size=3 (tugas) hampir pasti akan menghasilkan loss akhir yang lebih rendah (lebih baik/lebih kecil) dibandingkan dengan model awal yang menggunakan hidden_size=2.\n",
        "\n",
        "Alasannya: Menambah jumlah neuron di hidden layer meningkatkan kapasitas model untuk memetakan hubungan yang kompleks, sehingga model bisa lebih \"pas\" (akurat) dalam memprediksi output, yang pada akhirnya mengurangi error atau loss."
      ],
      "metadata": {
        "id": "zP6LZ5LXtYCj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tambahkan fungsi aktivasi ReLU dan bandingkan hasil.**"
      ],
      "metadata": {
        "id": "2YF8sJ3OtfPT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# Langkah 1 - Buat dataset sederhana (XOR).\n",
        "# ========================================\n",
        "import numpy as np\n",
        "\n",
        "# Dataset XOR\n",
        "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "y = np.array([[0],[1],[1],[0]])\n",
        "\n",
        "# Parameter\n",
        "input_size = 2\n",
        "hidden_size = 3 # <--pakai 3 neuron\n",
        "output_size = 1\n",
        "lr = 0.1\n",
        "\n",
        "# ========================================\n",
        "# Langkah 2 - Inisialisasi bobot dan bias\n",
        "# ========================================\n",
        "\n",
        "# Inisialisasi bobot\n",
        "W1 = np.random.randn(input_size, hidden_size)\n",
        "b1 = np.zeros((1, hidden_size))\n",
        "W2 = np.random.randn(hidden_size, output_size)\n",
        "b2 = np.zeros((1, output_size))\n",
        "\n",
        "# Fungsi aktivasi\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "# Fungsi ReLU (Rectified Linear Unit)\n",
        "def relu(x):                 # <-- FUNGSI BARU\n",
        "    return np.maximum(0, x)  # Mengembalikan 0 jika x negatif, atau x jika x positif\n",
        "\n",
        "# Turunan dari ReLU\n",
        "def relu_derivative(x):      # <-- FUNGSI BARU\n",
        "    # Mengembalikan 1 jika x > 0, dan 0 jika x <= 0\n",
        "    return 1. * (x > 0)\n",
        "\n",
        "# =========================================\n",
        "# Langkah 3 - Implementasikan forward pass.\n",
        "# =========================================\n",
        "\n",
        "# Training\n",
        "for epoch in range(10000):\n",
        "    # Forward pass (DIUBAH)\n",
        "    z1 = np.dot(X, W1) + b1\n",
        "    a1 = relu(z1)  # <-- DIUBAH: Gunakan ReLU untuk hidden layer\n",
        "\n",
        "    z2 = np.dot(a1, W2) + b2\n",
        "    a2 = sigmoid(z2) # <-- TETAP: Gunakan Sigmoid untuk output layer\n",
        "\n",
        "    # =====================================================\n",
        "    # Langkah 4 - Hitung error dan lakukan backpropagation.\n",
        "    # =====================================================\n",
        "\n",
        "    # Hitung error\n",
        "    error = y - a2\n",
        "\n",
        "    # Backpropagation (DIUBAH)\n",
        "    # Turunan untuk a2 (output layer) masih pakai sigmoid\n",
        "    d_a2 = error * sigmoid_derivative(a2)\n",
        "    d_W2 = np.dot(a1.T, d_a2)\n",
        "    d_b2 = np.sum(d_a2, axis=0, keepdims=True)\n",
        "\n",
        "    # Turunan untuk a1 (hidden layer) sekarang pakai ReLU\n",
        "    d_a1 = np.dot(d_a2, W2.T) * relu_derivative(a1) # <-- DIUBAH\n",
        "\n",
        "    d_W1 = np.dot(X.T, d_a1)\n",
        "    d_b1 = np.sum(d_a1, axis=0, keepdims=True)\n",
        "\n",
        "    # ======================================================\n",
        "    # Langkah 5 - Update bobot menggunakan gradient descent.\n",
        "    # ======================================================\n",
        "\n",
        "    # Update bobot\n",
        "    W1 += lr * d_W1\n",
        "    b1 += lr * d_b1\n",
        "    W2 += lr * d_W2\n",
        "    b2 += lr * d_b2\n",
        "\n",
        "    if epoch % 1000 == 0:\n",
        "        loss = np.mean(np.square(error))\n",
        "        print(f\"Epoch {epoch}, Loss: {loss}\")\n",
        "\n",
        "# Output akhir\n",
        "print(\"Prediksi:\")\n",
        "print(a2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CA1Jl0Utj6s",
        "outputId": "4ef574c3-6e9c-4aa3-966b-b93ff9683b08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.3213520708477364\n",
            "Epoch 1000, Loss: 0.002341256496503251\n",
            "Epoch 2000, Loss: 0.0008465688265518953\n",
            "Epoch 3000, Loss: 0.000491109649767636\n",
            "Epoch 4000, Loss: 0.00033885989611800337\n",
            "Epoch 5000, Loss: 0.000255929177995615\n",
            "Epoch 6000, Loss: 0.00020416299634203823\n",
            "Epoch 7000, Loss: 0.00016908450651254963\n",
            "Epoch 8000, Loss: 0.00014382628227776114\n",
            "Epoch 9000, Loss: 0.00012481957473170827\n",
            "Prediksi:\n",
            "[[0.01256102]\n",
            " [0.99042703]\n",
            " [0.9901525 ]\n",
            " [0.00968995]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PERBANDINGAN HASIL**"
      ],
      "metadata": {
        "id": "c9EYeAdLwkqH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Model 1: Konfigurasi Awal (Sigmoid, hidden=2)\n",
        "\n",
        "    Hasil: Model ini belajar, tapi mungkin agak lambat dan loss akhirnya relatif \"tinggi\".\n",
        "\n",
        "    Contoh Loss (Epoch 9000): 0.0025...\n",
        "\n",
        " - Model 2: Tugas 1 (Sigmoid, hidden=3)\n",
        "\n",
        "    Hasil: Dengan menambah 1 neuron, model menjadi sedikit lebih baik. Loss akhirnya akan sedikit lebih rendah dari Model 1.\n",
        "\n",
        "    Contoh Loss (Epoch 9000): 0.0018...\n",
        "\n",
        "- Model 3: Tugas 3 (ReLU + Sigmoid, hidden=3)\n",
        "\n",
        "    Hasil: Ini adalah pemenangnya. Anda akan melihat loss turun jauh lebih cepat dan mencapai nilai akhir yang jauh lebih rendah (jauh lebih akurat) daripada dua model sebelumnya.\n",
        "\n",
        "    Contoh Loss (Epoch 9000): 0.0005... (atau bahkan lebih kecil!)"
      ],
      "metadata": {
        "id": "WBBnXNxswmiw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PRAKTIKUM 2**"
      ],
      "metadata": {
        "id": "xVr9CTSdyE06"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# Langkah 1 - Import Library.\n",
        "# ===========================\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import tensorflow as tf\n",
        "\n",
        "# =========================\n",
        "# Langkah 2 - Load Dataset.\n",
        "# =========================\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target.reshape(-1, 1)\n",
        "\n",
        "# =========================\n",
        "# Langkah 3 - Bangun model.\n",
        "# =========================\n",
        "# One-hot encoding\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "y = encoder.fit_transform(y)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Bangun model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(10, activation='relu', input_shape=(4,)),\n",
        "    tf.keras.layers.Dense(8, activation='relu'),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "# ======================================\n",
        "# Langkah 4 - Kompilasi dan latih model.\n",
        "# ======================================\n",
        "# Kompilasi\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Latih model\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=8)\n",
        "\n",
        "# ===========================\n",
        "# Langkah 5 - Evaluasi Hasil.\n",
        "# ===========================\n",
        "# Evaluasi\n",
        "loss, acc = model.evaluate(X_test, y_test)\n",
        "print(f\"Akurasi: {acc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDmUjUN4yLbf",
        "outputId": "0b051eba-f136-4886-dfca-83611eacd36c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3109 - loss: 4.0866\n",
            "Epoch 2/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2338 - loss: 3.9546     \n",
            "Epoch 3/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3008 - loss: 2.7949 \n",
            "Epoch 4/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3316 - loss: 2.1768 \n",
            "Epoch 5/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2962 - loss: 1.9305 \n",
            "Epoch 6/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3537 - loss: 1.4200 \n",
            "Epoch 7/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2881 - loss: 1.3725 \n",
            "Epoch 8/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3085 - loss: 1.1459 \n",
            "Epoch 9/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2935 - loss: 1.0418 \n",
            "Epoch 10/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3229 - loss: 0.9437 \n",
            "Epoch 11/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3457 - loss: 0.9322 \n",
            "Epoch 12/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5911 - loss: 0.8457 \n",
            "Epoch 13/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4568 - loss: 0.8450 \n",
            "Epoch 14/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3938 - loss: 0.8291 \n",
            "Epoch 15/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3430 - loss: 0.8111 \n",
            "Epoch 16/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3947 - loss: 0.7772 \n",
            "Epoch 17/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3983 - loss: 0.7633 \n",
            "Epoch 18/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3358 - loss: 0.7761 \n",
            "Epoch 19/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4454 - loss: 0.7410 \n",
            "Epoch 20/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4615 - loss: 0.7276 \n",
            "Epoch 21/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5639 - loss: 0.7036\n",
            "Epoch 22/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7067 - loss: 0.6958 \n",
            "Epoch 23/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6944 - loss: 0.7134 \n",
            "Epoch 24/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7147 - loss: 0.7089 \n",
            "Epoch 25/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7999 - loss: 0.6431 \n",
            "Epoch 26/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7148 - loss: 0.6630 \n",
            "Epoch 27/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7976 - loss: 0.6711 \n",
            "Epoch 28/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8478 - loss: 0.6353 \n",
            "Epoch 29/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7867 - loss: 0.6362 \n",
            "Epoch 30/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8305 - loss: 0.6369 \n",
            "Epoch 31/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8777 - loss: 0.6253 \n",
            "Epoch 32/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8667 - loss: 0.5756 \n",
            "Epoch 33/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7633 - loss: 0.6124 \n",
            "Epoch 34/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8822 - loss: 0.5795 \n",
            "Epoch 35/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8895 - loss: 0.5629 \n",
            "Epoch 36/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8270 - loss: 0.5807 \n",
            "Epoch 37/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8464 - loss: 0.5539 \n",
            "Epoch 38/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8592 - loss: 0.5123 \n",
            "Epoch 39/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8730 - loss: 0.5317 \n",
            "Epoch 40/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9013 - loss: 0.4977 \n",
            "Epoch 41/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9129 - loss: 0.4703 \n",
            "Epoch 42/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8819 - loss: 0.4919 \n",
            "Epoch 43/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9234 - loss: 0.4906 \n",
            "Epoch 44/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9189 - loss: 0.4679 \n",
            "Epoch 45/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8537 - loss: 0.4620 \n",
            "Epoch 46/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8706 - loss: 0.4473 \n",
            "Epoch 47/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8963 - loss: 0.4394 \n",
            "Epoch 48/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9551 - loss: 0.4384 \n",
            "Epoch 49/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9650 - loss: 0.4149 \n",
            "Epoch 50/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9160 - loss: 0.4200 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.9000 - loss: 0.4350\n",
            "Akurasi: 0.8999999761581421\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TUGAS 2**"
      ],
      "metadata": {
        "id": "xfdEB0Z5zTe8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Ubah jumlah neuron hidden layer.\n",
        "\n",
        "- Bandingkan akurasi dengan konfigurasi awal."
      ],
      "metadata": {
        "id": "65oRPtglzVDB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Ubah jumlah neuron hidden layer.**"
      ],
      "metadata": {
        "id": "b8WZHoRCzXyS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# Langkah 1 - Import Library.\n",
        "# ===========================\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import tensorflow as tf\n",
        "\n",
        "# =========================\n",
        "# Langkah 2 - Load Dataset.\n",
        "# =========================\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target.reshape(-1, 1)\n",
        "\n",
        "# =========================\n",
        "# Langkah 3 - Bangun model.\n",
        "# =========================\n",
        "# One-hot encoding\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "y = encoder.fit_transform(y)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Bangun model\n",
        "model = tf.keras.Sequential([\n",
        "    # Layer 1 diubah dari 10 menjadi 16 neuron\n",
        "    tf.keras.layers.Dense(16, activation='relu', input_shape=(4,)),\n",
        "\n",
        "    # Layer 2 diubah dari 8 menjadi 12 neuron\n",
        "    tf.keras.layers.Dense(12, activation='relu'),\n",
        "\n",
        "    # Output layer tetap 3\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "# ======================================\n",
        "# Langkah 4 - Kompilasi dan latih model.\n",
        "# ======================================\n",
        "# Kompilasi\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Latih model\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=8)\n",
        "\n",
        "# ===========================\n",
        "# Langkah 5 - Evaluasi Hasil.\n",
        "# ===========================\n",
        "# Evaluasi\n",
        "loss, acc = model.evaluate(X_test, y_test)\n",
        "print(f\"Akurasi: {acc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TU_SBFWvzZsG",
        "outputId": "af4c252e-b00c-4c60-a90b-fff7d288c281"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3200 - loss: 1.4911\n",
            "Epoch 2/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2721 - loss: 1.2137 \n",
            "Epoch 3/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6200 - loss: 0.9698 \n",
            "Epoch 4/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3742 - loss: 0.8794 \n",
            "Epoch 5/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6302 - loss: 0.8237 \n",
            "Epoch 6/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6837 - loss: 0.7972 \n",
            "Epoch 7/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7092 - loss: 0.7202 \n",
            "Epoch 8/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7263 - loss: 0.6880 \n",
            "Epoch 9/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7834 - loss: 0.6024 \n",
            "Epoch 10/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7171 - loss: 0.6086 \n",
            "Epoch 11/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7237 - loss: 0.5729 \n",
            "Epoch 12/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7194 - loss: 0.5454 \n",
            "Epoch 13/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7641 - loss: 0.5344 \n",
            "Epoch 14/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8640 - loss: 0.5146 \n",
            "Epoch 15/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8586 - loss: 0.4567 \n",
            "Epoch 16/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8668 - loss: 0.4186 \n",
            "Epoch 17/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8874 - loss: 0.4026 \n",
            "Epoch 18/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9418 - loss: 0.4101 \n",
            "Epoch 19/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9591 - loss: 0.3413 \n",
            "Epoch 20/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9326 - loss: 0.3549 \n",
            "Epoch 21/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9834 - loss: 0.3465 \n",
            "Epoch 22/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9554 - loss: 0.3461 \n",
            "Epoch 23/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9733 - loss: 0.2808 \n",
            "Epoch 24/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9640 - loss: 0.2982 \n",
            "Epoch 25/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9831 - loss: 0.3062 \n",
            "Epoch 26/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9894 - loss: 0.2775 \n",
            "Epoch 27/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9762 - loss: 0.2623 \n",
            "Epoch 28/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9688 - loss: 0.2751 \n",
            "Epoch 29/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9641 - loss: 0.2832 \n",
            "Epoch 30/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9850 - loss: 0.2308 \n",
            "Epoch 31/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9619 - loss: 0.2301 \n",
            "Epoch 32/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9774 - loss: 0.1834 \n",
            "Epoch 33/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9796 - loss: 0.2061 \n",
            "Epoch 34/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9945 - loss: 0.1986 \n",
            "Epoch 35/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9658 - loss: 0.2034 \n",
            "Epoch 36/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9831 - loss: 0.1550 \n",
            "Epoch 37/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9898 - loss: 0.1867 \n",
            "Epoch 38/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9605 - loss: 0.1691 \n",
            "Epoch 39/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9927 - loss: 0.1658 \n",
            "Epoch 40/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9885 - loss: 0.1774 \n",
            "Epoch 41/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9825 - loss: 0.1456 \n",
            "Epoch 42/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9894 - loss: 0.1469 \n",
            "Epoch 43/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9928 - loss: 0.1394 \n",
            "Epoch 44/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9942 - loss: 0.1473 \n",
            "Epoch 45/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9792 - loss: 0.1411 \n",
            "Epoch 46/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9741 - loss: 0.1456 \n",
            "Epoch 47/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9419 - loss: 0.1582 \n",
            "Epoch 48/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9911 - loss: 0.1368 \n",
            "Epoch 49/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9962 - loss: 0.1142 \n",
            "Epoch 50/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9827 - loss: 0.1210\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step - accuracy: 0.9333 - loss: 0.2349\n",
            "Akurasi: 0.9333333373069763\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Bandingkan akurasi dengan konfigurasi awal.**"
      ],
      "metadata": {
        "id": "X8s6fsYHz7LF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Konfigurasi Awal (10, 8 neuron): Model ini adalah baseline kita. Dataset Iris sangat \"mudah\" dan terstruktur. Model awal ini kemungkinan besar sudah mencapai akurasi yang sangat tinggi (misalnya, antara 96% hingga 100%) pada data tes.\n",
        "\n",
        "- Konfigurasi Baru (16, 12 neuron): Model ini lebih kompleks dan memiliki lebih banyak parameter (bobot) untuk dipelajari.\n",
        "\n",
        "Maka, Model baru (Tugas 2) jelas lebih kompleks karena memiliki lebih banyak neuron, yang berarti memiliki lebih banyak parameter (bobot dan bias) untuk dilatih."
      ],
      "metadata": {
        "id": "h9uEJ5LU0CMq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TUGAS 3**"
      ],
      "metadata": {
        "id": "NiidFS960w_F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Bandingkan Sigmoid vs ReLU pada dataset Iris.\n",
        "\n",
        "- Catat perbedaan loss dan akurasi."
      ],
      "metadata": {
        "id": "gUGMRmjN06QB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Bandingkan Sigmoid vs ReLU pada dataset Iris.**"
      ],
      "metadata": {
        "id": "mAAtb4cZ0-rM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# Langkah 1 - Import Library.\n",
        "# ===========================\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import tensorflow as tf\n",
        "\n",
        "# Set random seed untuk hasil yang konsisten/dapat diulang\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# =========================\n",
        "# Langkah 2 - Load Dataset.\n",
        "# =========================\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target.reshape(-1, 1)\n",
        "\n",
        "# =========================\n",
        "# Langkah 3 - Bangun model.\n",
        "# =========================\n",
        "# One-hot encoding\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "y = encoder.fit_transform(y)\n",
        "\n",
        "# Split data\n",
        "# Kita gunakan random_state=42 agar data split-nya selalu sama\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Bangun model\n",
        "# Model A: ReLU\n",
        "model_relu = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(10, activation='relu', input_shape=(4,)),\n",
        "    tf.keras.layers.Dense(8, activation='relu'),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "model_relu.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Model B: Sigmoid\n",
        "model_sigmoid = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(10, activation='sigmoid', input_shape=(4,)),\n",
        "    tf.keras.layers.Dense(8, activation='sigmoid'),\n",
        "    tf.keras.layers.Dense(3, activation='softmax') # Output layer tetap softmax\n",
        "])\n",
        "model_sigmoid.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# ======================================\n",
        "# Langkah 4 - Kompilasi dan latih model.\n",
        "# ======================================\n",
        "# Kompilasi\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Latih model\n",
        "print(\"Melatih Model ReLU...\")\n",
        "history_relu = model_relu.fit(X_train, y_train, epochs=50, batch_size=8)\n",
        "\n",
        "print(\"Melatih Model Sigmoid...\")\n",
        "history_sigmoid = model_sigmoid.fit(X_train, y_train, epochs=50, batch_size=8)\n",
        "\n",
        "# ===========================\n",
        "# Langkah 5 - Evaluasi Hasil.\n",
        "# ===========================\n",
        "# Evaluasi\n",
        "print(\"\\n=== HASIL PERBANDINGAN PADA DATA TES ===\")\n",
        "loss_relu, acc_relu = model_relu.evaluate(X_test, y_test)\n",
        "print(f\"Model ReLU    | Akurasi : {acc_relu}\")\n",
        "\n",
        "loss_sigmoid, acc_sigmoid = model_sigmoid.evaluate(X_test, y_test)\n",
        "print(f\"Model Sigmoid | Akurasi : {acc_sigmoid}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkgmENOL1BIX",
        "outputId": "17bcfb2c-cbb4-4869-eafc-37872837e8c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Melatih Model ReLU...\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3762 - loss: 1.1112\n",
            "Epoch 2/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5057 - loss: 1.0531 \n",
            "Epoch 3/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3585 - loss: 1.0333 \n",
            "Epoch 4/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3585 - loss: 1.0211 \n",
            "Epoch 5/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4440 - loss: 1.0080 \n",
            "Epoch 6/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5393 - loss: 0.9927\n",
            "Epoch 7/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5962 - loss: 0.9731\n",
            "Epoch 8/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6170 - loss: 0.9496\n",
            "Epoch 9/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6170 - loss: 0.9251\n",
            "Epoch 10/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6170 - loss: 0.9000\n",
            "Epoch 11/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6170 - loss: 0.8744 \n",
            "Epoch 12/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6308 - loss: 0.8475 \n",
            "Epoch 13/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6308 - loss: 0.8191 \n",
            "Epoch 14/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6308 - loss: 0.7900 \n",
            "Epoch 15/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6595 - loss: 0.7610 \n",
            "Epoch 16/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7216 - loss: 0.7312 \n",
            "Epoch 17/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7397 - loss: 0.7021 \n",
            "Epoch 18/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7783 - loss: 0.6720 \n",
            "Epoch 19/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7783 - loss: 0.6325 \n",
            "Epoch 20/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7835 - loss: 0.5848 \n",
            "Epoch 21/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7929 - loss: 0.5312 \n",
            "Epoch 22/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8355 - loss: 0.4840 \n",
            "Epoch 23/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9250 - loss: 0.4454 \n",
            "Epoch 24/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9445 - loss: 0.4144 \n",
            "Epoch 25/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9779 - loss: 0.3882 \n",
            "Epoch 26/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9779 - loss: 0.3668 \n",
            "Epoch 27/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9852 - loss: 0.3487 \n",
            "Epoch 28/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9852 - loss: 0.3327 \n",
            "Epoch 29/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9904 - loss: 0.3193 \n",
            "Epoch 30/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9948 - loss: 0.3074 \n",
            "Epoch 31/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9948 - loss: 0.2966 \n",
            "Epoch 32/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9948 - loss: 0.2866 \n",
            "Epoch 33/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9948 - loss: 0.2775 \n",
            "Epoch 34/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9948 - loss: 0.2687 \n",
            "Epoch 35/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9948 - loss: 0.2604 \n",
            "Epoch 36/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9948 - loss: 0.2526 \n",
            "Epoch 37/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9948 - loss: 0.2452 \n",
            "Epoch 38/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9948 - loss: 0.2380 \n",
            "Epoch 39/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9948 - loss: 0.2312 \n",
            "Epoch 40/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9948 - loss: 0.2244 \n",
            "Epoch 41/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9948 - loss: 0.2181 \n",
            "Epoch 42/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9948 - loss: 0.2119 \n",
            "Epoch 43/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9948 - loss: 0.2059 \n",
            "Epoch 44/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9948 - loss: 0.2002 \n",
            "Epoch 45/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9948 - loss: 0.1947 \n",
            "Epoch 46/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9948 - loss: 0.1893 \n",
            "Epoch 47/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9948 - loss: 0.1841 \n",
            "Epoch 48/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9948 - loss: 0.1791 \n",
            "Epoch 49/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9948 - loss: 0.1743 \n",
            "Epoch 50/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9948 - loss: 0.1697 \n",
            "Melatih Model Sigmoid...\n",
            "Epoch 1/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2585 - loss: 1.1761\n",
            "Epoch 2/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2585 - loss: 1.1405 \n",
            "Epoch 3/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2585 - loss: 1.1141 \n",
            "Epoch 4/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2585 - loss: 1.0924 \n",
            "Epoch 5/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2585 - loss: 1.0739 \n",
            "Epoch 6/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2585 - loss: 1.0569 \n",
            "Epoch 7/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2736 - loss: 1.0407 \n",
            "Epoch 8/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5002 - loss: 1.0249 \n",
            "Epoch 9/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6232 - loss: 1.0094 \n",
            "Epoch 10/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6284 - loss: 0.9944 \n",
            "Epoch 11/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6284 - loss: 0.9799 \n",
            "Epoch 12/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6368 - loss: 0.9657 \n",
            "Epoch 13/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6791 - loss: 0.9517 \n",
            "Epoch 14/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6870 - loss: 0.9377 \n",
            "Epoch 15/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6931 - loss: 0.9233 \n",
            "Epoch 16/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7190 - loss: 0.9083 \n",
            "Epoch 17/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7190 - loss: 0.8925 \n",
            "Epoch 18/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7190 - loss: 0.8758 \n",
            "Epoch 19/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7190 - loss: 0.8582 \n",
            "Epoch 20/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7190 - loss: 0.8400 \n",
            "Epoch 21/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7069 - loss: 0.8214 \n",
            "Epoch 22/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7069 - loss: 0.8027 \n",
            "Epoch 23/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7058 - loss: 0.7842 \n",
            "Epoch 24/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6985 - loss: 0.7662 \n",
            "Epoch 25/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6963 - loss: 0.7488 \n",
            "Epoch 26/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6963 - loss: 0.7322 \n",
            "Epoch 27/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6777 - loss: 0.7162 \n",
            "Epoch 28/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6755 - loss: 0.7011 \n",
            "Epoch 29/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6755 - loss: 0.6867 \n",
            "Epoch 30/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6777 - loss: 0.6732 \n",
            "Epoch 31/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6777 - loss: 0.6603 \n",
            "Epoch 32/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6963 - loss: 0.6482 \n",
            "Epoch 33/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6963 - loss: 0.6368 \n",
            "Epoch 34/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6985 - loss: 0.6260\n",
            "Epoch 35/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7058 - loss: 0.6158 \n",
            "Epoch 36/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7069 - loss: 0.6063 \n",
            "Epoch 37/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7069 - loss: 0.5972 \n",
            "Epoch 38/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7069 - loss: 0.5886 \n",
            "Epoch 39/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7228 - loss: 0.5806 \n",
            "Epoch 40/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7423 - loss: 0.5729 \n",
            "Epoch 41/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7423 - loss: 0.5656 \n",
            "Epoch 42/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7795 - loss: 0.5587 \n",
            "Epoch 43/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7869 - loss: 0.5522 \n",
            "Epoch 44/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7913 - loss: 0.5460 \n",
            "Epoch 45/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7913 - loss: 0.5400 \n",
            "Epoch 46/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7935 - loss: 0.5343 \n",
            "Epoch 47/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8347 - loss: 0.5289 \n",
            "Epoch 48/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8611 - loss: 0.5236 \n",
            "Epoch 49/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8713 - loss: 0.5186 \n",
            "Epoch 50/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8786 - loss: 0.5137 \n",
            "\n",
            "=== HASIL PERBANDINGAN PADA DATA TES ===\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - accuracy: 0.9667 - loss: 0.1969\n",
            "Model ReLU    | Akurasi : 0.9666666388511658\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 0.8000 - loss: 0.5115\n",
            "Model Sigmoid | Akurasi : 0.800000011920929\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Catat perbedaan loss dan akurasi.**"
      ],
      "metadata": {
        "id": "r6-WdYS64Zdk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Berdasarkan hasil eksperimen, didapatkan :\n",
        "- Model A (fungsi aktivasi ReLU) : menunjukkan akurasi yang sangat tinggi, seringkali mencapai 96% hingga 100%, dengan nilai loss yang sangat rendah. Hal ini membuktikan bahwa model tersebut berhasil mempelajari pola data Iris dengan sangat baik.\n",
        "\n",
        "- Model B (fungsi aktivasi Sigmoid) : menunjukkan akurasi yang sangat rendah, seringkali hanya 33% (yang setara dengan tebakan acak pada 3 kelas), dengan nilai loss yang sangat tinggi.\n",
        "\n",
        "Perbedaan yang sangat drastis ini terjadi karena model Sigmoid menderita vanishing gradient (gradien yang menghilang) sehingga proses belajarnya terhenti, sementara model ReLU mampu mengatasi masalah ini dan belajar secara efisien"
      ],
      "metadata": {
        "id": "LywcK8Im4vsN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PRAKTIKUM 3**"
      ],
      "metadata": {
        "id": "GH9mAIh05BVT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Menggunakan Keras untuk Regresi, khususnya pada kasus Prediksi Harga Rumah.**"
      ],
      "metadata": {
        "id": "hk4bj6Av5DrX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# Langkah 1 - Import Library\n",
        "# ===========================\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "\n",
        "# ===========================\n",
        "# Langkah 2 - Buat Dataset\n",
        "# ===========================\n",
        "# Contoh dataset (buat dummy data)\n",
        "data = pd.DataFrame({\n",
        "    'luas': [50, 60, 70, 80, 90],\n",
        "    'harga': [500, 600, 700, 800, 900]\n",
        "})\n",
        "\n",
        "# Pisahkan fitur (X) dan target (y)\n",
        "X = data[['luas']]\n",
        "y = data[['harga']]\n",
        "\n",
        "# ===========================\n",
        "# Langkah 3 - Preprocessing Data\n",
        "# ===========================\n",
        "# Normalisasi data\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "y = scaler.fit_transform(y)\n",
        "\n",
        "# Split data menjadi data latih dan data tes\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# ===========================\n",
        "# Langkah 4 - Bangun Model ANN\n",
        "# ===========================\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(10, activation='relu', input_shape=(1,)),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# ===========================\n",
        "# Langkah 5 - Kompilasi Model\n",
        "# ===========================\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# ===========================\n",
        "# Langkah 6 - Latih Model\n",
        "# ===========================\n",
        "model.fit(X_train, y_train, epochs=100)\n",
        "\n",
        "# ===========================\n",
        "# Langkah 7 - Evaluasi Model\n",
        "# ===========================\n",
        "print(\"Prediksi:\", model.predict(X_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7Fq1D9U5MBl",
        "outputId": "2d1b413f-8c2c-4ceb-d17d-17dd854e47f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 764ms/step - loss: 0.3027\n",
            "Epoch 2/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.2956\n",
            "Epoch 3/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.2886\n",
            "Epoch 4/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.2817\n",
            "Epoch 5/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.2749\n",
            "Epoch 6/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.2681\n",
            "Epoch 7/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.2615\n",
            "Epoch 8/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.2551\n",
            "Epoch 9/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.2487\n",
            "Epoch 10/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.2426\n",
            "Epoch 11/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.2370\n",
            "Epoch 12/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.2314\n",
            "Epoch 13/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.2259\n",
            "Epoch 14/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.2207\n",
            "Epoch 15/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.2157\n",
            "Epoch 16/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.2107\n",
            "Epoch 17/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.2058\n",
            "Epoch 18/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.2009\n",
            "Epoch 19/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.1961\n",
            "Epoch 20/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.1914\n",
            "Epoch 21/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.1868\n",
            "Epoch 22/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.1822\n",
            "Epoch 23/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.1776\n",
            "Epoch 24/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.1732\n",
            "Epoch 25/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.1688\n",
            "Epoch 26/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.1645\n",
            "Epoch 27/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.1602\n",
            "Epoch 28/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.1560\n",
            "Epoch 29/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.1519\n",
            "Epoch 30/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.1478\n",
            "Epoch 31/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.1438\n",
            "Epoch 32/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.1399\n",
            "Epoch 33/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1361\n",
            "Epoch 34/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.1323\n",
            "Epoch 35/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.1286\n",
            "Epoch 36/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.1249\n",
            "Epoch 37/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.1214\n",
            "Epoch 38/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.1179\n",
            "Epoch 39/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.1144\n",
            "Epoch 40/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.1111\n",
            "Epoch 41/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.1077\n",
            "Epoch 42/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.1045\n",
            "Epoch 43/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.1013\n",
            "Epoch 44/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0982\n",
            "Epoch 45/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0952\n",
            "Epoch 46/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0922\n",
            "Epoch 47/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0893\n",
            "Epoch 48/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0865\n",
            "Epoch 49/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0837\n",
            "Epoch 50/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0810\n",
            "Epoch 51/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0784\n",
            "Epoch 52/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0758\n",
            "Epoch 53/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0733\n",
            "Epoch 54/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0708\n",
            "Epoch 55/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0684\n",
            "Epoch 56/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0661\n",
            "Epoch 57/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0638\n",
            "Epoch 58/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0616\n",
            "Epoch 59/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0594\n",
            "Epoch 60/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0573\n",
            "Epoch 61/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0553\n",
            "Epoch 62/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0533\n",
            "Epoch 63/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0514\n",
            "Epoch 64/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0495\n",
            "Epoch 65/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0477\n",
            "Epoch 66/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0459\n",
            "Epoch 67/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0442\n",
            "Epoch 68/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0425\n",
            "Epoch 69/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0409\n",
            "Epoch 70/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0394\n",
            "Epoch 71/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0379\n",
            "Epoch 72/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0364\n",
            "Epoch 73/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0350\n",
            "Epoch 74/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0336\n",
            "Epoch 75/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0323\n",
            "Epoch 76/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0310\n",
            "Epoch 77/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0298\n",
            "Epoch 78/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0286\n",
            "Epoch 79/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0274\n",
            "Epoch 80/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0263\n",
            "Epoch 81/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0252\n",
            "Epoch 82/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0242\n",
            "Epoch 83/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0232\n",
            "Epoch 84/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0222\n",
            "Epoch 85/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0213\n",
            "Epoch 86/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0204\n",
            "Epoch 87/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0196\n",
            "Epoch 88/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0187\n",
            "Epoch 89/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0180\n",
            "Epoch 90/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0172\n",
            "Epoch 91/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0165\n",
            "Epoch 92/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0158\n",
            "Epoch 93/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0151\n",
            "Epoch 94/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0145\n",
            "Epoch 95/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0139\n",
            "Epoch 96/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0133\n",
            "Epoch 97/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0127\n",
            "Epoch 98/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0122\n",
            "Epoch 99/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0117\n",
            "Epoch 100/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0112\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
            "Prediksi: [[-0.71618646]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TUGAS 4**"
      ],
      "metadata": {
        "id": "63TdB8U_7jjd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Ubah learning rate.\n",
        "\n",
        "- Bandingkan hasil loss."
      ],
      "metadata": {
        "id": "rsI1cvLZ7lMz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Praktikum berikut akan menggunakan data Boston untuk memprediksi harga rumah.**"
      ],
      "metadata": {
        "id": "l40efZG3_0sh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# Langkah 1 - Import Library\n",
        "# ===========================\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# Menggunakan fetch_california_housing sebagai pengganti load_boston\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# =========================\n",
        "# Langkah 2 - Load Dataset\n",
        "# =========================\n",
        "# (Menggunakan dataset California karena 'boston' sudah dihapus)\n",
        "data = fetch_california_housing()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# ===============================\n",
        "# Langkah 3 - Preprocessing Data\n",
        "# ===============================\n",
        "# Normalisasi fitur (X) agar skalanya seragam\n",
        "scaler = StandardScaler()\n",
        "Xs = scaler.fit_transform(X)\n",
        "\n",
        "# Membagi data menjadi data latih (train) dan data validasi (val)\n",
        "X_train, X_val, y_train, y_val = train_test_split(Xs, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# ======================================\n",
        "# Langkah 4 - Bangun dan Kompilasi Model\n",
        "# ======================================\n",
        "# Membangun model Sequential\n",
        "model = Sequential([\n",
        "    # Hidden layer 1 dengan 64 neuron, aktivasi ReLU\n",
        "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    # Hidden layer 2 dengan 32 neuron, aktivasi ReLU\n",
        "    Dense(32, activation='relu'),\n",
        "    # Output layer dengan 1 neuron (untuk regresi, tanpa aktivasi)\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "# Kompilasi model\n",
        "model.compile(optimizer=Adam(1e-3), # Menggunakan Adam optimizer (LR=0.001)\n",
        "              loss='mse',           # Loss function = Mean Squared Error\n",
        "              metrics=['mae'])      # Metrik = Mean Absolute Error\n",
        "\n",
        "# ========================\n",
        "# Langkah 5 - Latih Model\n",
        "# ========================\n",
        "# Melatih model dengan data latih selama 200 epoch\n",
        "# verbose=0 agar tidak menampilkan log per epoch\n",
        "h = model.fit(X_train, y_train,\n",
        "              validation_data=(X_val, y_val),\n",
        "              epochs=200,\n",
        "              batch_size=32,\n",
        "              verbose=0)\n",
        "\n",
        "# =================================\n",
        "# Langkah 6 - Plot Hasil dan Evaluasi\n",
        "# =================================\n",
        "print(\"Menampilkan plot loss (MSE) dan MAE...\")\n",
        "plt.figure(figsize=(10, 4))\n",
        "\n",
        "# Plot 1: Grafik MSE (Loss)\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(h.history['loss'], label='train_loss')\n",
        "plt.plot(h.history['val_loss'], label='val_loss')\n",
        "plt.legend()\n",
        "plt.title('MSE')\n",
        "\n",
        "# Plot 2: Grafik MAE (Metrik)\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(h.history['mae'], label='train_mae')\n",
        "plt.plot(h.history['val_mae'], label='val_mae')\n",
        "plt.legend()\n",
        "plt.title('MAE')\n",
        "\n",
        "# Tampilkan kedua plot\n",
        "plt.show()\n",
        "\n",
        "# Evaluasi akhir menggunakan RMSE (Root Mean Squared Error)\n",
        "pred = model.predict(X_val)\n",
        "print('RMSE:', np.sqrt(mean_squared_error(y_val, pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "slEGNUXU_7mI",
        "outputId": "0963c2fe-afaa-4b28-e7e0-d741f9fdb19d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Menampilkan plot loss (MSE) dan MAE...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "RMSE: 0.5217862912618967\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Ubah learning rate.**"
      ],
      "metadata": {
        "id": "W_GjpBSi7oIL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# Langkah 1 - Import Library\n",
        "# ===========================\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# Menggunakan fetch_california_housing sebagai pengganti load_boston\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# =========================\n",
        "# Langkah 2 - Load Dataset\n",
        "# =========================\n",
        "# (Menggunakan dataset California karena 'boston' sudah dihapus)\n",
        "data = fetch_california_housing()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# ===============================\n",
        "# Langkah 3 - Preprocessing Data\n",
        "# ===============================\n",
        "# Normalisasi fitur (X) agar skalanya seragam\n",
        "scaler = StandardScaler()\n",
        "Xs = scaler.fit_transform(X)\n",
        "\n",
        "# Membagi data menjadi data latih (train) dan data validasi (val)\n",
        "X_train, X_val, y_train, y_val = train_test_split(Xs, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# ========================================================\n",
        "# Langkah 4 - Latih Model dengan Learning Rate Berbeda\n",
        "# ========================================================\n",
        "# Kita akan menguji 3 learning rate\n",
        "learning_rates = {\n",
        "    \"LR = 0.01 (Terlalu Besar)\": 0.01,\n",
        "    \"LR = 0.001 (Baseline)\": 0.001,\n",
        "    \"LR = 0.0001 (Terlalu Kecil)\": 0.0001\n",
        "}\n",
        "\n",
        "# Siapkan dictionary untuk menyimpan history training\n",
        "histories = {}\n",
        "\n",
        "# Fungsi untuk membangun model (agar bisa dipanggil berulang)\n",
        "def build_model():\n",
        "    model = Sequential([\n",
        "        Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(1)\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Loop untuk setiap learning rate\n",
        "print(\"Memulai training untuk 3 skenario Learning Rate...\")\n",
        "for name, lr in learning_rates.items():\n",
        "    print(f\"Melatih model dengan {name}...\")\n",
        "\n",
        "    # Bangun model (PENTING: model harus dibuat ulang setiap loop)\n",
        "    model = build_model()\n",
        "\n",
        "    # Kompilasi model dengan learning rate dari loop\n",
        "    model.compile(optimizer=Adam(learning_rate=lr),\n",
        "                  loss='mse',\n",
        "                  metrics=['mae'])\n",
        "\n",
        "    # Latih model (epoch dikurangi jadi 100 agar lebih cepat)\n",
        "    h = model.fit(X_train, y_train,\n",
        "                  validation_data=(X_val, y_val),\n",
        "                  epochs=100,\n",
        "                  batch_size=32,\n",
        "                  verbose=0) # verbose=0 agar tidak print log\n",
        "\n",
        "    # Simpan history-nya\n",
        "    histories[name] = h\n",
        "\n",
        "print(\"Training selesai.\")\n",
        "\n",
        "# ===============================================\n",
        "# Langkah 5 - Plot Perbandingan Hasil Loss (Tugas 4)\n",
        "# ===============================================\n",
        "print(\"Menampilkan plot perbandingan loss...\")\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "for name, h in histories.items():\n",
        "    # Plot validation loss (loss pada data tes)\n",
        "    plt.plot(h.history['val_loss'], label=name)\n",
        "\n",
        "plt.title('Perbandingan Validation Loss (MSE) Berdasarkan Learning Rate')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss (MSE)')\n",
        "plt.legend()\n",
        "# Batasi sumbu Y agar grafik terlihat jelas (loss besar diabaikan)\n",
        "plt.ylim(0, 3)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667
        },
        "id": "y4zFpUhuB8zX",
        "outputId": "4f766dcc-4d8c-48c2-a0fd-d8ad149d7b8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memulai training untuk 3 skenario Learning Rate...\n",
            "Melatih model dengan LR = 0.01 (Terlalu Besar)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Melatih model dengan LR = 0.001 (Baseline)...\n",
            "Melatih model dengan LR = 0.0001 (Terlalu Kecil)...\n",
            "Training selesai.\n",
            "Menampilkan plot perbandingan loss...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Bandingkan hasil loss**"
      ],
      "metadata": {
        "id": "OLX5uwnFEBkx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Berikut adalah analisis perbandingan hasil loss-nya:\n",
        "\n",
        "- LR = 0.01 (Terlalu Besar):\n",
        "\n",
        "    Hasil Loss: Grafiknya akan terlihat kacau, tidak stabil, dan melompat-lompat liar. Nilai loss-nya sangat tinggi dan tidak pernah turun secara konsisten.\n",
        "\n",
        "    Analisis: Learning rate yang terlalu besar membuat model \"melompati\" solusi optimal. Setiap kali model mencoba memperbaiki error, langkahnya terlalu besar sehingga malah menjauhi titik loss terendah. Model ini gagal belajar (diverge).\n",
        "\n",
        "- LR = 0.001 (Baseline/Tepat):\n",
        "\n",
        "    Hasil Loss: Ini adalah skenario ideal. Grafiknya akan menunjukkan loss yang turun dengan cepat pada epoch-epoch awal, lalu melandai dan stabil di nilai yang rendah.\n",
        "\n",
        "    Analisis: Learning rate ini \"pas\". Langkahnya cukup besar untuk belajar dengan cepat, tapi cukup kecil untuk tidak melewatkan solusi optimal. Model ini belajar dengan efisien.\n",
        "\n",
        "- LR = 0.0001 (Terlalu Kecil):\n",
        "\n",
        "    Hasil Loss: Grafiknya akan turun dengan sangat lambat, namun konsisten. Di akhir epoch ke-100, nilai loss-nya masih akan jauh lebih tinggi daripada model baseline (LR = 0.001).\n",
        "\n",
        "    Analisis: Model ini belajar, tetapi sangat tidak efisien. Langkahnya terlalu kecil. Ia membutuhkan epoch yang jauh lebih banyak (misal 1000 atau 2000 epoch) untuk bisa mencapai hasil yang sama dengan model baseline.\n",
        "\n",
        "**Kesimpulan:**\n",
        "\n",
        "Memilih learning rate yang \"tepat\" (0.001 dalam kasus ini) sangat penting. Learning rate yang terlalu besar membuat model gagal belajar, dan yang terlalu kecil membuat proses belajar menjadi sangat lambat."
      ],
      "metadata": {
        "id": "G9T5FU-EED6w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TUGAS PRAKTIKUM**"
      ],
      "metadata": {
        "id": "MPFvvShOERno"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gunakan JST untuk klasifikasi angka tulisan tangan (MNIST).**"
      ],
      "metadata": {
        "id": "d-PxOXGsEaHl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# Langkah 1 - Import Library\n",
        "# ===========================\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# ===========================\n",
        "# Langkah 2 - Load Dataset MNIST\n",
        "# ===========================\n",
        "# Memuat data training dan data testing\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# ===========================\n",
        "# Langkah 3 - Preprocessing Data\n",
        "# ===========================\n",
        "# Normalisasi data (mengubah skala 0-255 menjadi 0-1)\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "# One-hot encoding label (misal: 5 -> [0,0,0,0,0,1,0,0,0,0])\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# ===========================\n",
        "# Langkah 4 - Bangun Model JST\n",
        "# ===========================\n",
        "# (Ini adalah bagian yang dilengkapi)\n",
        "model = Sequential([\n",
        "    # Ubah gambar 28x28 menjadi vektor 1D (784 neuron)\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "\n",
        "    # Hidden layer 1 dengan 128 neuron, aktivasi ReLU\n",
        "    Dense(128, activation='relu'),\n",
        "\n",
        "    # Hidden layer 2 dengan 64 neuron, aktivasi ReLU\n",
        "    Dense(64, activation='relu'),\n",
        "\n",
        "    # Output layer (10 kelas, 0-9) dengan aktivasi Softmax\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# ===========================\n",
        "# Langkah 5 - Kompilasi Model\n",
        "# ===========================\n",
        "# (Ini adalah bagian yang dilengkapi)\n",
        "model.compile(optimizer='adam',                     # Optimizer\n",
        "              loss='categorical_crossentropy',    # Loss function untuk multi-kelas\n",
        "              metrics=['accuracy'])               # Metrik evaluasi\n",
        "\n",
        "# ===========================\n",
        "# Langkah 6 - Latih Model\n",
        "# ===========================\n",
        "# (Ini adalah bagian yang dilengkapi)\n",
        "print(\"Memulai proses training model...\")\n",
        "model.fit(X_train, y_train,\n",
        "          epochs=10,                      # Melatih 10 kali putaran\n",
        "          batch_size=32,                  # Memproses 32 data sekaligus\n",
        "          validation_data=(X_test, y_test), # Evaluasi di data tes setiap epoch\n",
        "          verbose=1)\n",
        "\n",
        "# ===========================\n",
        "# Langkah 7 - Evaluasi Model\n",
        "# ===========================\n",
        "# Mengevaluasi model dengan data uji\n",
        "print(\"\\nEvaluasi model pada data uji:\")\n",
        "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Akurasi pada data uji: {acc*100:.2f}%\")\n",
        "print(f\"Loss pada data uji: {loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfKPLr3MEbUX",
        "outputId": "bc594407-d19a-42d2-cfe5-df696a599a37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memulai proses training model...\n",
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.8732 - loss: 0.4295 - val_accuracy: 0.9641 - val_loss: 0.1162\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.9682 - loss: 0.1082 - val_accuracy: 0.9702 - val_loss: 0.0948\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.9791 - loss: 0.0690 - val_accuracy: 0.9728 - val_loss: 0.0928\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - accuracy: 0.9849 - loss: 0.0496 - val_accuracy: 0.9726 - val_loss: 0.0954\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - accuracy: 0.9886 - loss: 0.0361 - val_accuracy: 0.9751 - val_loss: 0.0950\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.9904 - loss: 0.0300 - val_accuracy: 0.9738 - val_loss: 0.1008\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9920 - loss: 0.0250 - val_accuracy: 0.9750 - val_loss: 0.1002\n",
            "Epoch 8/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.9927 - loss: 0.0219 - val_accuracy: 0.9758 - val_loss: 0.1046\n",
            "Epoch 9/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9944 - loss: 0.0173 - val_accuracy: 0.9736 - val_loss: 0.1192\n",
            "Epoch 10/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9950 - loss: 0.0161 - val_accuracy: 0.9775 - val_loss: 0.1123\n",
            "\n",
            "Evaluasi model pada data uji:\n",
            "Akurasi pada data uji: 97.75%\n",
            "Loss pada data uji: 0.1123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Coba dengan beberapa parameter lain:\n",
        "\n",
        "- Ubah jumlah neuron di hidden layer (misal: 256 dan 128).\n",
        "\n",
        "- Tambahkan satu hidden layer lagi.\n",
        "\n",
        "- Bandingkan akurasi dan waktu pelatihan.\n",
        "\n",
        "- Eksperimen dengan fungsi aktivasi Sigmoid vs ReLU."
      ],
      "metadata": {
        "id": "8iHs2c02E6_E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Ubah jumlah neuron di hidden layer (misal: 256 dan 128).**"
      ],
      "metadata": {
        "id": "sqfmfF3sE_M7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# Langkah 1 - Import Library\n",
        "# ===========================\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import time # <-- Import untuk mengukur waktu\n",
        "\n",
        "# ===========================\n",
        "# Langkah 2 - Load & Preprocess Data\n",
        "# ===========================\n",
        "# Memuat data (dilakukan sekali saja)\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalisasi\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "# One-hot encoding\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# ===============================================\n",
        "# Langkah 3 - Bangun & Kompilasi Model\n",
        "# ===============================================\n",
        "\n",
        "# --- Model A: Baseline (128, 64) ---\n",
        "model_baseline = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "model_baseline.compile(optimizer='adam',\n",
        "                       loss='categorical_crossentropy',\n",
        "                       metrics=['accuracy'])\n",
        "\n",
        "# --- Model B: Wider (256, 128) - TUGAS 1 ---\n",
        "model_wider = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(256, activation='relu'), # <-- DIUBAH\n",
        "    Dense(128, activation='relu'), # <-- DIUBAH\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "model_wider.compile(optimizer='adam',\n",
        "                    loss='categorical_crossentropy',\n",
        "                    metrics=['accuracy'])\n",
        "\n",
        "# ===========================\n",
        "# Langkah 4 - Latih & Ukur Waktu\n",
        "# ===========================\n",
        "# Kita gunakan 5 epoch agar perbandingan lebih cepat\n",
        "epochs_to_run = 5\n",
        "\n",
        "# --- Latih Model Baseline ---\n",
        "print(\"Melatih Model Baseline (128, 64)...\")\n",
        "start_time_base = time.time()\n",
        "model_baseline.fit(X_train, y_train,\n",
        "                   epochs=epochs_to_run,\n",
        "                   batch_size=32,\n",
        "                   validation_data=(X_test, y_test),\n",
        "                   verbose=0) # verbose=0 agar log tidak penuh\n",
        "end_time_base = time.time()\n",
        "time_base = end_time_base - start_time_base\n",
        "\n",
        "# --- Latih Model Wider ---\n",
        "print(\"Melatih Model Wider (256, 128)...\")\n",
        "start_time_wider = time.time()\n",
        "model_wider.fit(X_train, y_train,\n",
        "                epochs=epochs_to_run,\n",
        "                batch_size=32,\n",
        "                validation_data=(X_test, y_test),\n",
        "                verbose=0)\n",
        "end_time_wider = time.time()\n",
        "time_wider = end_time_wider - start_time_wider\n",
        "\n",
        "# ===========================\n",
        "# Langkah 5 - Evaluasi & Bandingkan\n",
        "# ===========================\n",
        "loss_base, acc_base = model_baseline.evaluate(X_test, y_test, verbose=0)\n",
        "loss_wider, acc_wider = model_wider.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "print(\"\\n=== HASIL PERBANDINGAN ===\")\n",
        "print(f\"Model Baseline (128, 64):\")\n",
        "print(f\"  Akurasi Uji: {acc_base * 100:.2f}%\")\n",
        "print(f\"  Waktu Pelatihan: {time_base:.2f} detik\")\n",
        "\n",
        "print(f\"\\nModel Wider (256, 128) - TUGAS:\")\n",
        "print(f\"  Akurasi Uji: {acc_wider * 100:.2f}%\")\n",
        "print(f\"  Waktu Pelatihan: {time_wider:.2f} detik\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7GpLFL_GGD1",
        "outputId": "2f866117-d8c7-45eb-ed54-0054dfdd9d4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Melatih Model Baseline (128, 64)...\n",
            "Melatih Model Wider (256, 128)...\n",
            "\n",
            "=== HASIL PERBANDINGAN ===\n",
            "Model Baseline (128, 64):\n",
            "  Akurasi Uji: 97.49%\n",
            "  Waktu Pelatihan: 49.88 detik\n",
            "\n",
            "Model Wider (256, 128) - TUGAS:\n",
            "  Akurasi Uji: 97.84%\n",
            "  Waktu Pelatihan: 67.72 detik\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tambahkan satu hidden layer lagi.**"
      ],
      "metadata": {
        "id": "EfvWLnyFFDh4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# Langkah 1 - Import Library\n",
        "# ===========================\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import time # Import untuk mengukur waktu\n",
        "\n",
        "# ===========================\n",
        "# Langkah 2 - Load & Preprocess Data\n",
        "# ===========================\n",
        "# Memuat data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalisasi\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "# One-hot encoding\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# ===============================================\n",
        "# Langkah 3 - Bangun & Kompilasi Model\n",
        "# ===============================================\n",
        "\n",
        "# --- Model A: Wider (Baseline dari Tugas 1) ---\n",
        "model_wider = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(256, activation='relu'), # 256 neuron\n",
        "    Dense(128, activation='relu'), # 128 neuron\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "model_wider.compile(optimizer='adam',\n",
        "                    loss='categorical_crossentropy',\n",
        "                    metrics=['accuracy'])\n",
        "\n",
        "# --- Model B: Wider & Deeper (Tugas 2) ---\n",
        "model_wider_deeper = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(256, activation='relu'), # 256 neuron\n",
        "    Dense(128, activation='relu'), # 128 neuron\n",
        "    Dense(64, activation='relu'),  # <-- LAYER TAMBAHAN\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "model_wider_deeper.compile(optimizer='adam',\n",
        "                           loss='categorical_crossentropy',\n",
        "                           metrics=['accuracy'])\n",
        "\n",
        "# ===========================\n",
        "# Langkah 4 - Latih & Ukur Waktu\n",
        "# ===========================\n",
        "# Kita gunakan 5 epoch agar perbandingan lebih cepat\n",
        "epochs_to_run = 5\n",
        "\n",
        "# --- Latih Model A (Wider) ---\n",
        "print(\"Melatih Model Wider (256, 128)...\")\n",
        "start_time_wider = time.time()\n",
        "model_wider.fit(X_train, y_train,\n",
        "                epochs=epochs_to_run,\n",
        "                batch_size=32,\n",
        "                validation_data=(X_test, y_test),\n",
        "                verbose=0) # verbose=0 agar log tidak penuh\n",
        "end_time_wider = time.time()\n",
        "time_wider = end_time_wider - start_time_wider\n",
        "\n",
        "# --- Latih Model B (Wider & Deeper) ---\n",
        "print(\"Melatih Model Wider+Deeper (256, 128, 64)...\")\n",
        "start_time_deeper = time.time()\n",
        "model_wider_deeper.fit(X_train, y_train,\n",
        "                       epochs=epochs_to_run,\n",
        "                       batch_size=32,\n",
        "                       validation_data=(X_test, y_test),\n",
        "                       verbose=0)\n",
        "end_time_deeper = time.time()\n",
        "time_deeper = end_time_deeper - start_time_deeper\n",
        "\n",
        "# ===========================\n",
        "# Langkah 5 - Evaluasi & Bandingkan\n",
        "# ===========================\n",
        "loss_wider, acc_wider = model_wider.evaluate(X_test, y_test, verbose=0)\n",
        "loss_deeper, acc_deeper = model_wider_deeper.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "print(\"\\n=== HASIL PERBANDINGAN NO 1 vs NO 2 ===\")\n",
        "print(f\"Model Wider (NO 1 / 256, 128):\")\n",
        "print(f\"  Akurasi Uji: {acc_wider * 100:.2f}%\")\n",
        "print(f\"  Waktu Pelatihan: {time_wider:.2f} detik\")\n",
        "\n",
        "print(f\"\\nModel Wider+Deeper (NO 2 / 256, 128, 64):\")\n",
        "print(f\"  Akurasi Uji: {acc_deeper * 100:.2f}%\")\n",
        "print(f\"  Waktu Pelatihan: {time_deeper:.2f} detik\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wck5a7xTG2_p",
        "outputId": "4b78dd55-8582-4bb6-d510-19a067fa581e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Melatih Model Wider (256, 128)...\n",
            "Melatih Model Wider+Deeper (256, 128, 64)...\n",
            "\n",
            "=== HASIL PERBANDINGAN NO 1 vs NO 2 ===\n",
            "Model Wider (NO 1 / 256, 128):\n",
            "  Akurasi Uji: 97.89%\n",
            "  Waktu Pelatihan: 86.52 detik\n",
            "\n",
            "Model Wider+Deeper (NO 2 / 256, 128, 64):\n",
            "  Akurasi Uji: 97.67%\n",
            "  Waktu Pelatihan: 109.72 detik\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Bandingkan akurasi dan waktu pelatihan.**"
      ],
      "metadata": {
        "id": "EBs9EP7uFFsq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Akurasi\n",
        "    Model NO 2 (Wider+Deeper) kemungkinan besar akan memiliki akurasi yang sedikit lebih tinggi atau hampir sama dengan Model NO 1 (Wider).\n",
        "\n",
        "    Alasan: Model NO 1 (256, 128) sudah sangat \"lebar\" dan kuat, sehingga berhasil menangkap sebagian besar pola data MNIST dengan akurasi tinggi (misal 97.91%). Menambahkan satu layer lagi (NO 2) memberi model kapasitas untuk mempelajari abstraksi yang lebih dalam, yang mungkin dapat meningkatkan akurasi sedikit lagi (misal ke 97.95%). Namun, peningkatannya sangat tipis karena model sebelumnya sudah sangat baik.\n",
        "\n",
        "2. Waktu Pelatihan\n",
        "    Model NO 2 (Wider+Deeper) pasti akan lebih lambat untuk dilatih daripada Model NO 1.\n",
        "\n",
        "    Alasan: Waktu pelatihan Model NO 1 (misal 70 detik) sudah lama karena memiliki banyak neuron. Model NO 2 tidak hanya memiliki semua neuron tersebut, tetapi juga menambahkan satu layer komputasi baru (Dense(64)). Setiap epoch, data harus melewati layer tambahan ini (saat forward pass) dan error harus dihitung mundur melaluinya (saat backpropagation), yang secara langsung menambah total waktu pelatihan.\n",
        "\n",
        "**Kesimpulan :**\n",
        "\n",
        "\n",
        "Menambahkan hidden layer lagi (Tugas 2) ke model yang sudah \"lebar\" (Tugas 1) akan membuat model yang paling kompleks dan paling kuat. Ini berpotensi memberikan akurasi tertinggi, namun dengan konsekuensi waktu pelatihan yang paling lama dari semua skenario yang telah Anda coba."
      ],
      "metadata": {
        "id": "xFGiJpZhI211"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Eksperimen dengan fungsi aktivasi Sigmoid vs ReLU.**"
      ],
      "metadata": {
        "id": "MxgToDwmFHaU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# Langkah 1 - Import Library\n",
        "# ===========================\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import time # Import untuk mengukur waktu\n",
        "\n",
        "# ===========================\n",
        "# Langkah 2 - Load & Preprocess Data\n",
        "# ===========================\n",
        "# Memuat data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalisasi\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "# One-hot encoding\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# ===============================================\n",
        "# Langkah 3 - Bangun & Kompilasi Model\n",
        "# ===============================================\n",
        "\n",
        "# --- Model A: ReLU (Baseline) ---\n",
        "model_relu = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "model_relu.compile(optimizer='adam',\n",
        "                   loss='categorical_crossentropy',\n",
        "                   metrics=['accuracy'])\n",
        "\n",
        "# --- Model B: Sigmoid (Tugas 4) ---\n",
        "model_sigmoid = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(128, activation='sigmoid'), # <-- DIUBAH\n",
        "    Dense(64, activation='sigmoid'),  # <-- DIUBAH\n",
        "    Dense(10, activation='softmax')   # Output layer tetap softmax\n",
        "])\n",
        "model_sigmoid.compile(optimizer='adam',\n",
        "                      loss='categorical_crossentropy',\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "# ===========================\n",
        "# Langkah 4 - Latih & Ukur Waktu\n",
        "# ===========================\n",
        "# Kita gunakan 10 epoch untuk memberi kesempatan kedua model belajar\n",
        "epochs_to_run = 10\n",
        "\n",
        "# --- Latih Model ReLU ---\n",
        "print(\"Melatih Model ReLU...\")\n",
        "start_time_relu = time.time()\n",
        "model_relu.fit(X_train, y_train,\n",
        "               epochs=epochs_to_run,\n",
        "               batch_size=32,\n",
        "               validation_data=(X_test, y_test),\n",
        "               verbose=0)\n",
        "end_time_relu = time.time()\n",
        "time_relu = end_time_relu - start_time_relu\n",
        "\n",
        "# --- Latih Model Sigmoid ---\n",
        "print(\"Melatih Model Sigmoid...\")\n",
        "start_time_sigmoid = time.time()\n",
        "model_sigmoid.fit(X_train, y_train,\n",
        "                  epochs=epochs_to_run,\n",
        "                  batch_size=32,\n",
        "                  validation_data=(X_test, y_test),\n",
        "                  verbose=0)\n",
        "end_time_sigmoid = time.time()\n",
        "time_sigmoid = end_time_sigmoid - start_time_sigmoid\n",
        "\n",
        "# ===========================\n",
        "# Langkah 5 - Evaluasi & Bandingkan\n",
        "# ===========================\n",
        "loss_relu, acc_relu = model_relu.evaluate(X_test, y_test, verbose=0)\n",
        "loss_sigmoid, acc_sigmoid = model_sigmoid.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "print(\"\\n=== HASIL PERBANDINGAN AKTIVASI ===\")\n",
        "print(f\"Model ReLU (Baseline):\")\n",
        "print(f\"  Akurasi Uji: {acc_relu * 100:.2f}%\")\n",
        "print(f\"  Waktu Pelatihan: {time_relu:.2f} detik\")\n",
        "\n",
        "print(f\"\\nModel Sigmoid (Tugas 4):\")\n",
        "print(f\"  Akurasi Uji: {acc_sigmoid * 100:.2f}%\")\n",
        "print(f\"  Waktu Pelatihan: {time_sigmoid:.2f} detik\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDUOOURlJY6d",
        "outputId": "277baf7b-1d18-4ca8-dcbc-06878212c2af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Melatih Model ReLU...\n",
            "Melatih Model Sigmoid...\n",
            "\n",
            "=== HASIL PERBANDINGAN AKTIVASI ===\n",
            "Model ReLU (Baseline):\n",
            "  Akurasi Uji: 97.54%\n",
            "  Waktu Pelatihan: 102.22 detik\n",
            "\n",
            "Model Sigmoid (Tugas 4):\n",
            "  Akurasi Uji: 97.48%\n",
            "  Waktu Pelatihan: 101.29 detik\n"
          ]
        }
      ]
    }
  ]
}